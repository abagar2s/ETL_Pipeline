# 🌤️ Weather & Air Pollution ETL Pipeline with Airflow & PostgreSQL  

This project automates the extraction, transformation, and loading (**ETL**) of **real-time weather and air pollution data** using **Apache Airflow** and stores the processed data in **PostgreSQL**.

---

## 📌 1. Overview  

This **ETL pipeline** performs the following tasks:  

✔ **Extracts** real-time weather data from the [OpenWeatherMap API](https://openweathermap.org/)  
✔ **Extracts** air pollution data using latitude/longitude coordinates  
✔ **Transforms** data into a structured format  
✔ **Loads & stores** weather and air quality data into a **PostgreSQL database**  
✔ **Automates** execution using **Apache Airflow**  
✔ **Logs** operations for debugging & monitoring  

---

## ⚙ 2. Tech Stack  

🔹 **Python** - Used for API requests, data transformation & PostgreSQL interaction  
🔹 **Apache Airflow** - DAG orchestration & scheduling  
🔹 **PostgreSQL** - Storing structured weather & air pollution data  
🔹 **Logging** - To track execution & errors  

---

## 🔄 3. Workflow Steps  

1️⃣ **Fetch Weather Data** → Calls OpenWeatherMap API for real-time weather  
2️⃣ **Fetch Air Pollution Data** → Fetches AQI, CO, NO2, O3, PM2.5 levels  
3️⃣ **Transform Data** → Extracts key information (temperature, humidity, air quality, etc.)  
4️⃣ **Store in PostgreSQL** → Saves data in structured tables  
5️⃣ **Schedule with Airflow** → Runs **hourly** automatically  

---

## 📁 4. Project Structure  

```plaintext
📂 Weather_ETL_Airflow/
├── 📄 etl_dag.py                # Airflow DAG definition
├── 📄 requirements.txt          # Python dependencies
├── 📄 .gitignore                # Excludes venv/ & sensitive files
├── 📄 README.md                 # Project documentation
├── 📄 pipeline.log              # Log file for debugging
└── 📂 airflow/                  # Airflow home directory
```

## 🗄️ 5. PostgreSQL Database Schema  

### 📌 Weather Table (`weather`)  

```sql
CREATE TABLE IF NOT EXISTS weather (
    id SERIAL PRIMARY KEY,
    city TEXT,
    date TIMESTAMP,
    temperature REAL,
    feels_like REAL,
    humidity REAL,
    pressure REAL,
    weather_condition TEXT,
    weather_description TEXT
);
```
📌 Air Pollution Table (air_pollution)

```sql
CREATE TABLE IF NOT EXISTS air_pollution (
    id SERIAL PRIMARY KEY,
    aqi INTEGER,
    co REAL,
    no2 REAL,
    o3 REAL,
    pm2_5 REAL
);
```
## 🚀 6. Setup & Run Instructions  

### 1️⃣ Clone the Repository  

```bash
git clone https://github.com/YOUR_USERNAME/Weather_ETL_Airflow.git
cd Weather_ETL_Airflow
```

### 2️⃣ Set Up Virtual Environment & Install Dependencies
```bash
python -m venv airflow_env
source airflow_env/bin/activate  # macOS/Linux
airflow_env\Scripts\activate     # Windows

pip install -r requirements.txt
```

### 3️⃣ Set Up Airflow
```bash
export AIRFLOW_HOME=$(pwd)/airflow  # Set Airflow home directory
airflow db init                     # Initialize Airflow database
airflow users create --username admin --password admin --role Admin --firstname Air --lastname Flow --email admin@example.com
```

### 4️⃣ Start Airflow Webserver & Scheduler

```bash
airflow webserver --port 8080  # Runs Airflow UI
airflow scheduler              # Starts DAG execution
```
### 5️⃣ Monitor DAG in Airflow UI

    Open http://localhost:8080 in your browser
    Activate the DAG weather_air_pollution_pipeline
    Monitor execution & logs
