# ğŸŒ¤ï¸ Weather & Air Pollution ETL Pipeline with Airflow & PostgreSQL  

This project automates the extraction, transformation, and loading (**ETL**) of **real-time weather and air pollution data** using **Apache Airflow** and stores the processed data in **PostgreSQL**.

---

## ğŸ“Œ 1. Overview  

This **ETL pipeline** performs the following tasks:  

âœ” **Extracts** real-time weather data from the [OpenWeatherMap API](https://openweathermap.org/)  
âœ” **Extracts** air pollution data using latitude/longitude coordinates  
âœ” **Transforms** data into a structured format  
âœ” **Loads & stores** weather and air quality data into a **PostgreSQL database**  
âœ” **Automates** execution using **Apache Airflow**  
âœ” **Logs** operations for debugging & monitoring  

---

## âš™ 2. Tech Stack  

ğŸ”¹ **Python** - Used for API requests, data transformation & PostgreSQL interaction  
ğŸ”¹ **Apache Airflow** - DAG orchestration & scheduling  
ğŸ”¹ **PostgreSQL** - Storing structured weather & air pollution data  
ğŸ”¹ **Logging** - To track execution & errors  

---

## ğŸ”„ 3. Workflow Steps  

1ï¸âƒ£ **Fetch Weather Data** â†’ Calls OpenWeatherMap API for real-time weather  
2ï¸âƒ£ **Fetch Air Pollution Data** â†’ Fetches AQI, CO, NO2, O3, PM2.5 levels  
3ï¸âƒ£ **Transform Data** â†’ Extracts key information (temperature, humidity, air quality, etc.)  
4ï¸âƒ£ **Store in PostgreSQL** â†’ Saves data in structured tables  
5ï¸âƒ£ **Schedule with Airflow** â†’ Runs **hourly** automatically  

---

## ğŸ“ 4. Project Structure  

```plaintext
ğŸ“‚ Weather_ETL_Airflow/
â”œâ”€â”€ ğŸ“„ etl_dag.py                # Airflow DAG definition
â”œâ”€â”€ ğŸ“„ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸ“„ .gitignore                # Excludes venv/ & sensitive files
â”œâ”€â”€ ğŸ“„ README.md                 # Project documentation
â”œâ”€â”€ ğŸ“„ pipeline.log              # Log file for debugging
â””â”€â”€ ğŸ“‚ airflow/                  # Airflow home directory
```

## ğŸ—„ï¸ 5. PostgreSQL Database Schema  

### ğŸ“Œ Weather Table (`weather`)  

```sql
CREATE TABLE IF NOT EXISTS weather (
    id SERIAL PRIMARY KEY,
    city TEXT,
    date TIMESTAMP,
    temperature REAL,
    feels_like REAL,
    humidity REAL,
    pressure REAL,
    weather_condition TEXT,
    weather_description TEXT
);
```
ğŸ“Œ Air Pollution Table (air_pollution)

```sql
CREATE TABLE IF NOT EXISTS air_pollution (
    id SERIAL PRIMARY KEY,
    aqi INTEGER,
    co REAL,
    no2 REAL,
    o3 REAL,
    pm2_5 REAL
);
```
## ğŸš€ 6. Setup & Run Instructions  

### 1ï¸âƒ£ Clone the Repository  

```bash
git clone https://github.com/YOUR_USERNAME/Weather_ETL_Airflow.git
cd Weather_ETL_Airflow
```

### 2ï¸âƒ£ Set Up Virtual Environment & Install Dependencies
```bash
python -m venv airflow_env
source airflow_env/bin/activate  # macOS/Linux
airflow_env\Scripts\activate     # Windows

pip install -r requirements.txt
```

### 3ï¸âƒ£ Set Up Airflow
```bash
export AIRFLOW_HOME=$(pwd)/airflow  # Set Airflow home directory
airflow db init                     # Initialize Airflow database
airflow users create --username admin --password admin --role Admin --firstname Air --lastname Flow --email admin@example.com
```

### 4ï¸âƒ£ Start Airflow Webserver & Scheduler

```bash
airflow webserver --port 8080  # Runs Airflow UI
airflow scheduler              # Starts DAG execution
```
### 5ï¸âƒ£ Monitor DAG in Airflow UI

    Open http://localhost:8080 in your browser
    Activate the DAG weather_air_pollution_pipeline
    Monitor execution & logs
